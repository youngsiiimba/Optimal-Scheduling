{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epc3Eh5onjI6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hcsFNskAn4iX"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Machine Learning Microgrid Data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNKFI9cIX61p"
      },
      "source": [
        "### Encode Categorical Columns\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/386/1*Yp6r7m82IoSnnZDPpDpYNw.png\" width=\"640\">\n",
        "\n",
        "Let's one-hot encode categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXQqbrSa8nE8",
        "outputId": "d064aaff-0f8c-49f1-f2da-63227937367d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Battery',\n",
              " 'Diesel Wind',\n",
              " 'Diesel',\n",
              " 'Wind',\n",
              " 'Battery Wind',\n",
              " 'Diesel Solar Wind',\n",
              " 'Battery Diesel',\n",
              " 'Battery Diesel Solar',\n",
              " 'Battery Diesel Solar Wind',\n",
              " 'Battery Solar Wind',\n",
              " 'Battery Solar',\n",
              " 'Solar Wind',\n",
              " 'Solar']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "possible_combinations = list(df['Output power (Sources)'].unique())\n",
        "possible_combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHhp6w1e6r5F"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df['Output power (Sources)'] = le.fit_transform(df['Output power (Sources)'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhnphWj57LjE",
        "outputId": "6ca15418-52b5-4209-bc79-4a324c3d953f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 9, 7, 12, 6, 8, 1, 2, 3, 5, 4, 11, 10]"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(df['Output power (Sources)'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "_5ll9lsp6zoT",
        "outputId": "55cf5bfd-5de7-4b79-b580-cc617beb1b5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-839f2847-2c01-4f58-a152-9fb7a8504d85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Solar Power (MW)</th>\n",
              "      <th>Diesel Generator Power (MW)</th>\n",
              "      <th>Battery Power (MW)</th>\n",
              "      <th>Wind Power (MW)</th>\n",
              "      <th>Load Profile (MW)</th>\n",
              "      <th>Output power (MW)</th>\n",
              "      <th>Output power (Sources)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-0.481781</td>\n",
              "      <td>-13.622404</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.672488</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.155444e-30</td>\n",
              "      <td>-0.481781</td>\n",
              "      <td>-13.622404</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.672488</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.155136e-08</td>\n",
              "      <td>-0.474034</td>\n",
              "      <td>-13.893489</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.516805</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.846541e-07</td>\n",
              "      <td>-0.458889</td>\n",
              "      <td>-14.413524</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.212482</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.077568e-07</td>\n",
              "      <td>-0.444237</td>\n",
              "      <td>-14.900612</td>\n",
              "      <td>1</td>\n",
              "      <td>-8.918097</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-839f2847-2c01-4f58-a152-9fb7a8504d85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-839f2847-2c01-4f58-a152-9fb7a8504d85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-839f2847-2c01-4f58-a152-9fb7a8504d85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Time  Solar Power (MW)  Diesel Generator Power (MW)  \\\n",
              "0  0.000000e+00         -0.481781                   -13.622404   \n",
              "1  3.155444e-30         -0.481781                   -13.622404   \n",
              "2  6.155136e-08         -0.474034                   -13.893489   \n",
              "3  1.846541e-07         -0.458889                   -14.413524   \n",
              "4  3.077568e-07         -0.444237                   -14.900612   \n",
              "\n",
              "   Battery Power (MW)  Wind Power (MW)  Load Profile (MW)  Output power (MW)  \\\n",
              "0                   1        -9.672488                0.9                1.0   \n",
              "1                   1        -9.672488                0.9                1.0   \n",
              "2                   1        -9.516805                0.9                1.0   \n",
              "3                   1        -9.212482                0.9                1.0   \n",
              "4                   1        -8.918097                0.9                1.0   \n",
              "\n",
              "   Output power (Sources)  \n",
              "0                       0  \n",
              "1                       0  \n",
              "2                       0  \n",
              "3                       0  \n",
              "4                       0  "
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnZZtegz7eaL",
        "outputId": "4915bb91-7fd0-4f0f-c64d-d6d5272ca3ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Battery', 'Diesel Wind', 'Diesel', 'Wind', 'Battery Wind',\n",
              "       'Diesel Solar Wind', 'Battery Diesel', 'Battery Diesel Solar',\n",
              "       'Battery Diesel Solar Wind', 'Battery Solar Wind', 'Battery Solar',\n",
              "       'Solar Wind', 'Solar'], dtype=object)"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.inverse_transform([0, 9, 7, 12, 6, 8, 1, 2, 3, 5, 4, 11, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Q4DlLIoEI6"
      },
      "outputs": [],
      "source": [
        "input_cols = ['Solar Power (MW)', 'Diesel Generator Power (MW)', 'Battery Power (MW)', 'Wind Power (MW)', 'Load Profile (MW)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGcx3-trob13"
      },
      "outputs": [],
      "source": [
        "regression_target_cols = ['Output power (MW)']\n",
        "classification_target_cols = ['Output power (Sources)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytIZgQ3Zohyx"
      },
      "outputs": [],
      "source": [
        "inputs = df[input_cols]\n",
        "regression_targets = df[regression_target_cols]\n",
        "classification_targets = df[classification_target_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWD83nTfQpRL"
      },
      "outputs": [],
      "source": [
        "numeric_cols = ['Solar Power (MW)', 'Diesel Generator Power (MW)', 'Battery Power (MW)', 'Wind Power (MW)', 'Load Profile (MW)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhxzbj7cQ3wu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "XR_train, XR_test, yr_train, yr_test = train_test_split(\n",
        " inputs, regression_targets, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaasXHBEQ70u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "XC_train, XC_test, yc_train, yc_test = train_test_split(\n",
        " inputs, classification_targets, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3d_8Wd38ANc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax22Hyn2CUjJ"
      },
      "source": [
        "###Neural network Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj4dpg8VDf_A"
      },
      "source": [
        "####Model design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6ywoGaQbCTGH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "NN_regression_model = tf.keras.Sequential()\n",
        "NN_regression_model.add(layers.Dense(80, activation='relu', input_shape=(inputs.shape[1],)) )\n",
        "NN_regression_model.add(layers.Dense(40, activation='relu'))\n",
        "NN_regression_model.add(layers.Dense(1))\n",
        "\n",
        "NN_regression_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "NN_regression_model.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdUkQ3zTDkiV",
        "outputId": "1e0c3c03-5546-4cd0-910f-c1fa0b58b297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 80)                480       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                3240      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,761\n",
            "Trainable params: 3,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "NN_regression_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XKDJDdJDxJO"
      },
      "source": [
        "####Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr7BXskKDzHU",
        "outputId": "30055d95-7fe9-42e1-80bc-1d04a551317b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "250/250 [==============================] - 4s 3ms/step - loss: 0.6689 - accuracy: 0.3985 - val_loss: 0.1177 - val_accuracy: 0.4353\n",
            "Epoch 2/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.4121 - val_loss: 0.0538 - val_accuracy: 0.4353\n",
            "Epoch 3/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.4117 - val_loss: 0.0247 - val_accuracy: 0.4353\n",
            "Epoch 4/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.4113 - val_loss: 0.0376 - val_accuracy: 0.4353\n",
            "Epoch 5/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.4105 - val_loss: 0.0427 - val_accuracy: 0.4353\n",
            "Epoch 6/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.4105 - val_loss: 0.0163 - val_accuracy: 0.4353\n",
            "Epoch 7/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.4117 - val_loss: 0.0168 - val_accuracy: 0.4353\n",
            "Epoch 8/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.4109 - val_loss: 0.0246 - val_accuracy: 0.4317\n",
            "Epoch 9/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.4113 - val_loss: 0.0132 - val_accuracy: 0.4353\n",
            "Epoch 10/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 0.4117 - val_loss: 0.0213 - val_accuracy: 0.4353\n",
            "Epoch 11/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.4121 - val_loss: 0.0141 - val_accuracy: 0.4353\n",
            "Epoch 12/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0249 - accuracy: 0.4113 - val_loss: 0.0117 - val_accuracy: 0.4353\n",
            "Epoch 13/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.4121 - val_loss: 0.0119 - val_accuracy: 0.4353\n",
            "Epoch 14/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.4113 - val_loss: 0.0129 - val_accuracy: 0.4353\n",
            "Epoch 15/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.4117 - val_loss: 0.0282 - val_accuracy: 0.4353\n",
            "Epoch 16/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.4097 - val_loss: 0.0324 - val_accuracy: 0.4353\n",
            "Epoch 17/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.4121 - val_loss: 0.0372 - val_accuracy: 0.4353\n",
            "Epoch 18/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.4121 - val_loss: 0.0114 - val_accuracy: 0.4353\n",
            "Epoch 19/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.4105 - val_loss: 0.0140 - val_accuracy: 0.4353\n",
            "Epoch 20/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0194 - accuracy: 0.4121 - val_loss: 0.0099 - val_accuracy: 0.4353\n",
            "Epoch 21/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.4121 - val_loss: 0.0121 - val_accuracy: 0.4353\n",
            "Epoch 22/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.4117 - val_loss: 0.0114 - val_accuracy: 0.4353\n",
            "Epoch 23/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.4105 - val_loss: 0.0255 - val_accuracy: 0.4353\n",
            "Epoch 24/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.4117 - val_loss: 0.0071 - val_accuracy: 0.4353\n",
            "Epoch 25/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.4121 - val_loss: 0.0100 - val_accuracy: 0.4353\n",
            "Epoch 26/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.4121 - val_loss: 0.0112 - val_accuracy: 0.4353\n",
            "Epoch 27/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.4121 - val_loss: 0.0208 - val_accuracy: 0.4353\n",
            "Epoch 28/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0210 - accuracy: 0.4121 - val_loss: 0.0070 - val_accuracy: 0.4353\n",
            "Epoch 29/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.4117 - val_loss: 0.0282 - val_accuracy: 0.4353\n",
            "Epoch 30/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.4117 - val_loss: 0.0097 - val_accuracy: 0.4353\n",
            "Epoch 31/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.4113 - val_loss: 0.0099 - val_accuracy: 0.4353\n",
            "Epoch 32/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.4117 - val_loss: 0.0172 - val_accuracy: 0.4353\n",
            "Epoch 33/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.4109 - val_loss: 0.0078 - val_accuracy: 0.4353\n",
            "Epoch 34/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.4109 - val_loss: 0.0101 - val_accuracy: 0.4353\n",
            "Epoch 35/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.4113 - val_loss: 0.0355 - val_accuracy: 0.4353\n",
            "Epoch 36/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.4113 - val_loss: 0.0178 - val_accuracy: 0.4353\n",
            "Epoch 37/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.4121 - val_loss: 0.0097 - val_accuracy: 0.4353\n",
            "Epoch 38/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.4121 - val_loss: 0.0153 - val_accuracy: 0.4353\n",
            "Epoch 39/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0160 - accuracy: 0.4117 - val_loss: 0.0083 - val_accuracy: 0.4353\n",
            "Epoch 40/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0155 - accuracy: 0.4121 - val_loss: 0.0215 - val_accuracy: 0.4353\n",
            "Epoch 41/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.4121 - val_loss: 0.0065 - val_accuracy: 0.4353\n",
            "Epoch 42/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0156 - accuracy: 0.4121 - val_loss: 0.0082 - val_accuracy: 0.4353\n",
            "Epoch 43/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.4109 - val_loss: 0.0156 - val_accuracy: 0.4353\n",
            "Epoch 44/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.4117 - val_loss: 0.0120 - val_accuracy: 0.4353\n",
            "Epoch 45/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.4117 - val_loss: 0.0084 - val_accuracy: 0.4353\n",
            "Epoch 46/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.4117 - val_loss: 0.0064 - val_accuracy: 0.4353\n",
            "Epoch 47/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0136 - accuracy: 0.4121 - val_loss: 0.0043 - val_accuracy: 0.4353\n",
            "Epoch 48/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.4117 - val_loss: 0.0082 - val_accuracy: 0.4353\n",
            "Epoch 49/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.4121 - val_loss: 0.0068 - val_accuracy: 0.4353\n",
            "Epoch 50/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.4121 - val_loss: 0.0052 - val_accuracy: 0.4353\n",
            "Epoch 51/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.4117 - val_loss: 0.0076 - val_accuracy: 0.4353\n",
            "Epoch 52/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.4117 - val_loss: 0.0165 - val_accuracy: 0.4353\n",
            "Epoch 53/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.4117 - val_loss: 0.0091 - val_accuracy: 0.4353\n",
            "Epoch 54/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.4117 - val_loss: 0.0055 - val_accuracy: 0.4353\n",
            "Epoch 55/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.4121 - val_loss: 0.0045 - val_accuracy: 0.4353\n",
            "Epoch 56/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.4121 - val_loss: 0.0138 - val_accuracy: 0.4353\n",
            "Epoch 57/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.4121 - val_loss: 0.0075 - val_accuracy: 0.4353\n",
            "Epoch 58/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.4121 - val_loss: 0.0095 - val_accuracy: 0.4353\n",
            "Epoch 59/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.4121 - val_loss: 0.0033 - val_accuracy: 0.4353\n",
            "Epoch 60/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0127 - accuracy: 0.4117 - val_loss: 0.0109 - val_accuracy: 0.4353\n",
            "Epoch 61/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.4121 - val_loss: 0.0098 - val_accuracy: 0.4353\n",
            "Epoch 62/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.4121 - val_loss: 0.0054 - val_accuracy: 0.4353\n",
            "Epoch 63/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0108 - accuracy: 0.4121 - val_loss: 0.0133 - val_accuracy: 0.4353\n",
            "Epoch 64/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.4117 - val_loss: 0.0039 - val_accuracy: 0.4353\n",
            "Epoch 65/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.4121 - val_loss: 0.0040 - val_accuracy: 0.4353\n",
            "Epoch 66/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.4121 - val_loss: 0.0048 - val_accuracy: 0.4353\n",
            "Epoch 67/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.4121 - val_loss: 0.0078 - val_accuracy: 0.4353\n",
            "Epoch 68/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0156 - accuracy: 0.4117 - val_loss: 0.0035 - val_accuracy: 0.4353\n",
            "Epoch 69/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.4121 - val_loss: 0.0045 - val_accuracy: 0.4353\n",
            "Epoch 70/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.4121 - val_loss: 0.0174 - val_accuracy: 0.4353\n",
            "Epoch 71/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.4117 - val_loss: 0.0030 - val_accuracy: 0.4353\n",
            "Epoch 72/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.4121 - val_loss: 0.0044 - val_accuracy: 0.4353\n",
            "Epoch 73/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.4121 - val_loss: 0.0116 - val_accuracy: 0.4353\n",
            "Epoch 74/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.4121 - val_loss: 0.0144 - val_accuracy: 0.4353\n",
            "Epoch 75/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.4117 - val_loss: 0.0070 - val_accuracy: 0.4353\n",
            "Epoch 76/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.4121 - val_loss: 0.0076 - val_accuracy: 0.4353\n",
            "Epoch 77/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.4117 - val_loss: 0.0042 - val_accuracy: 0.4353\n",
            "Epoch 78/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.4121 - val_loss: 0.0087 - val_accuracy: 0.4353\n",
            "Epoch 79/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.4121 - val_loss: 0.0032 - val_accuracy: 0.4353\n",
            "Epoch 80/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.4121 - val_loss: 0.0085 - val_accuracy: 0.4353\n",
            "Epoch 81/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.4121 - val_loss: 0.0043 - val_accuracy: 0.4353\n",
            "Epoch 82/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.4121 - val_loss: 0.0068 - val_accuracy: 0.4353\n",
            "Epoch 83/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.4121 - val_loss: 0.0082 - val_accuracy: 0.4353\n",
            "Epoch 84/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.4121 - val_loss: 0.0125 - val_accuracy: 0.4353\n",
            "Epoch 85/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.4117 - val_loss: 0.0049 - val_accuracy: 0.4353\n",
            "Epoch 86/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.4121 - val_loss: 0.0055 - val_accuracy: 0.4353\n",
            "Epoch 87/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.4121 - val_loss: 0.0080 - val_accuracy: 0.4353\n",
            "Epoch 88/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.4121 - val_loss: 0.0115 - val_accuracy: 0.4353\n",
            "Epoch 89/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.4121 - val_loss: 0.0098 - val_accuracy: 0.4353\n",
            "Epoch 90/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.4121 - val_loss: 0.0076 - val_accuracy: 0.4353\n",
            "Epoch 91/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.4121 - val_loss: 0.0063 - val_accuracy: 0.4353\n",
            "Epoch 92/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.4121 - val_loss: 0.0065 - val_accuracy: 0.4353\n",
            "Epoch 93/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0108 - accuracy: 0.4121 - val_loss: 0.0100 - val_accuracy: 0.4353\n",
            "Epoch 94/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.4121 - val_loss: 0.0055 - val_accuracy: 0.4353\n",
            "Epoch 95/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.4121 - val_loss: 0.0053 - val_accuracy: 0.4353\n",
            "Epoch 96/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.4121 - val_loss: 0.0040 - val_accuracy: 0.4353\n",
            "Epoch 97/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.4121 - val_loss: 0.0085 - val_accuracy: 0.4353\n",
            "Epoch 98/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.4121 - val_loss: 0.0035 - val_accuracy: 0.4353\n",
            "Epoch 99/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.4117 - val_loss: 0.0053 - val_accuracy: 0.4353\n",
            "Epoch 100/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.4121 - val_loss: 0.0040 - val_accuracy: 0.4353\n",
            "Epoch 101/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.4121 - val_loss: 0.0083 - val_accuracy: 0.4353\n",
            "Epoch 102/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0108 - accuracy: 0.4117 - val_loss: 0.0062 - val_accuracy: 0.4353\n",
            "Epoch 103/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.4121 - val_loss: 0.0128 - val_accuracy: 0.4353\n",
            "Epoch 104/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.4121 - val_loss: 0.0085 - val_accuracy: 0.4353\n",
            "Epoch 105/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.4121 - val_loss: 0.0071 - val_accuracy: 0.4353\n",
            "Epoch 106/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.4121 - val_loss: 0.0090 - val_accuracy: 0.4353\n",
            "Epoch 107/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.4117 - val_loss: 0.0041 - val_accuracy: 0.4353\n",
            "Epoch 108/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.4121 - val_loss: 0.0122 - val_accuracy: 0.4353\n",
            "Epoch 109/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.4121 - val_loss: 0.0053 - val_accuracy: 0.4353\n",
            "Epoch 110/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.4121 - val_loss: 0.0086 - val_accuracy: 0.4353\n",
            "Epoch 111/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.4121 - val_loss: 0.0060 - val_accuracy: 0.4353\n",
            "Epoch 112/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.4121 - val_loss: 0.0105 - val_accuracy: 0.4353\n",
            "Epoch 113/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.4117 - val_loss: 0.0036 - val_accuracy: 0.4353\n",
            "Epoch 114/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.4121 - val_loss: 0.0020 - val_accuracy: 0.4353\n",
            "Epoch 115/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.4121 - val_loss: 0.0053 - val_accuracy: 0.4353\n",
            "Epoch 116/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.4121 - val_loss: 0.0029 - val_accuracy: 0.4353\n",
            "Epoch 117/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.4121 - val_loss: 0.0089 - val_accuracy: 0.4353\n",
            "Epoch 118/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.4121 - val_loss: 0.0035 - val_accuracy: 0.4353\n",
            "Epoch 119/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.4121 - val_loss: 0.0134 - val_accuracy: 0.4353\n",
            "Epoch 120/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.4121 - val_loss: 0.0015 - val_accuracy: 0.4353\n",
            "Epoch 121/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.4121 - val_loss: 0.0025 - val_accuracy: 0.4353\n",
            "Epoch 122/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.4121 - val_loss: 0.0028 - val_accuracy: 0.4353\n",
            "Epoch 123/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.4121 - val_loss: 0.0048 - val_accuracy: 0.4353\n",
            "Epoch 124/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.4121 - val_loss: 0.0074 - val_accuracy: 0.4353\n",
            "Epoch 125/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.4121 - val_loss: 0.0097 - val_accuracy: 0.4353\n",
            "Epoch 126/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.4121 - val_loss: 0.0095 - val_accuracy: 0.4353\n",
            "Epoch 127/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.4121 - val_loss: 0.0050 - val_accuracy: 0.4353\n",
            "Epoch 128/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.4121 - val_loss: 0.0077 - val_accuracy: 0.4353\n",
            "Epoch 129/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.4121 - val_loss: 0.0038 - val_accuracy: 0.4353\n",
            "Epoch 130/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.4121 - val_loss: 0.0086 - val_accuracy: 0.4353\n",
            "Epoch 131/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.4117 - val_loss: 0.0071 - val_accuracy: 0.4353\n",
            "Epoch 132/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.4121 - val_loss: 0.0060 - val_accuracy: 0.4353\n",
            "Epoch 133/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.4121 - val_loss: 0.0053 - val_accuracy: 0.4353\n",
            "Epoch 134/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.4121 - val_loss: 0.0040 - val_accuracy: 0.4353\n",
            "Epoch 135/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.4121 - val_loss: 0.0037 - val_accuracy: 0.4353\n",
            "Epoch 136/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.4121 - val_loss: 0.0045 - val_accuracy: 0.4353\n",
            "Epoch 137/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.4121 - val_loss: 0.0081 - val_accuracy: 0.4353\n",
            "Epoch 138/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.4121 - val_loss: 0.0051 - val_accuracy: 0.4353\n",
            "Epoch 139/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.4117 - val_loss: 0.0047 - val_accuracy: 0.4353\n",
            "Epoch 140/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.4121 - val_loss: 0.0062 - val_accuracy: 0.4353\n",
            "Epoch 141/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.4121 - val_loss: 0.0088 - val_accuracy: 0.4353\n",
            "Epoch 142/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.4121 - val_loss: 0.0029 - val_accuracy: 0.4353\n",
            "Epoch 143/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.4121 - val_loss: 0.0040 - val_accuracy: 0.4353\n",
            "Epoch 144/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.4121 - val_loss: 0.0043 - val_accuracy: 0.4353\n",
            "Epoch 145/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.4121 - val_loss: 0.0060 - val_accuracy: 0.4353\n",
            "Epoch 146/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.4121 - val_loss: 0.0039 - val_accuracy: 0.4353\n",
            "Epoch 147/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.4121 - val_loss: 0.0076 - val_accuracy: 0.4353\n",
            "Epoch 148/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.4121 - val_loss: 0.0089 - val_accuracy: 0.4353\n",
            "Epoch 149/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.4121 - val_loss: 0.0015 - val_accuracy: 0.4353\n",
            "Epoch 150/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.4121 - val_loss: 0.0056 - val_accuracy: 0.4353\n",
            "Epoch 151/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0119 - accuracy: 0.4113 - val_loss: 0.0042 - val_accuracy: 0.4353\n",
            "Epoch 152/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.4121 - val_loss: 0.0090 - val_accuracy: 0.4353\n",
            "Epoch 153/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.4121 - val_loss: 0.0060 - val_accuracy: 0.4353\n",
            "Epoch 154/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.4121 - val_loss: 0.0067 - val_accuracy: 0.4353\n",
            "Epoch 155/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.4121 - val_loss: 0.0058 - val_accuracy: 0.4353\n",
            "Epoch 156/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.4121 - val_loss: 0.0094 - val_accuracy: 0.4353\n",
            "Epoch 157/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.4121 - val_loss: 0.0014 - val_accuracy: 0.4353\n",
            "Epoch 158/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.4121 - val_loss: 0.0019 - val_accuracy: 0.4353\n",
            "Epoch 159/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.4121 - val_loss: 0.0054 - val_accuracy: 0.4353\n",
            "Epoch 160/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.4121 - val_loss: 0.0088 - val_accuracy: 0.4353\n",
            "Epoch 161/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.4121 - val_loss: 0.0044 - val_accuracy: 0.4353\n",
            "Epoch 162/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.4121 - val_loss: 0.0078 - val_accuracy: 0.4353\n",
            "Epoch 163/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.4121 - val_loss: 0.0011 - val_accuracy: 0.4353\n",
            "Epoch 164/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.4121 - val_loss: 0.0059 - val_accuracy: 0.4353\n",
            "Epoch 165/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.4121 - val_loss: 0.0019 - val_accuracy: 0.4353\n",
            "Epoch 166/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.4121 - val_loss: 0.0016 - val_accuracy: 0.4353\n",
            "Epoch 167/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.4121 - val_loss: 0.0070 - val_accuracy: 0.4353\n",
            "Epoch 168/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.4121 - val_loss: 0.0021 - val_accuracy: 0.4353\n",
            "Epoch 169/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.4121 - val_loss: 0.0082 - val_accuracy: 0.4353\n",
            "Epoch 170/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.4121 - val_loss: 0.0041 - val_accuracy: 0.4353\n",
            "Epoch 171/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.4121 - val_loss: 0.0132 - val_accuracy: 0.4353\n",
            "Epoch 172/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.4121 - val_loss: 0.0084 - val_accuracy: 0.4353\n",
            "Epoch 173/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.4121 - val_loss: 0.0044 - val_accuracy: 0.4353\n",
            "Epoch 174/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.4121 - val_loss: 0.0037 - val_accuracy: 0.4353\n",
            "Epoch 175/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.4121 - val_loss: 0.0058 - val_accuracy: 0.4353\n",
            "Epoch 176/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.4121 - val_loss: 0.0043 - val_accuracy: 0.4353\n",
            "Epoch 177/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.4121 - val_loss: 0.0026 - val_accuracy: 0.4353\n",
            "Epoch 178/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.4121 - val_loss: 0.0029 - val_accuracy: 0.4353\n",
            "Epoch 179/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.4121 - val_loss: 0.0033 - val_accuracy: 0.4353\n",
            "Epoch 180/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.4121 - val_loss: 0.0020 - val_accuracy: 0.4353\n",
            "Epoch 181/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.4121 - val_loss: 0.0031 - val_accuracy: 0.4353\n",
            "Epoch 182/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.4121 - val_loss: 0.0030 - val_accuracy: 0.4353\n",
            "Epoch 183/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.4121 - val_loss: 0.0027 - val_accuracy: 0.4353\n",
            "Epoch 184/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.4121 - val_loss: 0.0055 - val_accuracy: 0.4353\n",
            "Epoch 185/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.4121 - val_loss: 0.0054 - val_accuracy: 0.4353\n",
            "Epoch 186/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.4121 - val_loss: 0.0077 - val_accuracy: 0.4353\n",
            "Epoch 187/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.4121 - val_loss: 0.0066 - val_accuracy: 0.4353\n",
            "Epoch 188/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.4121 - val_loss: 0.0021 - val_accuracy: 0.4353\n",
            "Epoch 189/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.4121 - val_loss: 0.0018 - val_accuracy: 0.4353\n",
            "Epoch 190/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.4121 - val_loss: 0.0023 - val_accuracy: 0.4353\n",
            "Epoch 191/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.4121 - val_loss: 0.0100 - val_accuracy: 0.4353\n",
            "Epoch 192/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.4121 - val_loss: 0.0093 - val_accuracy: 0.4353\n",
            "Epoch 193/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.4121 - val_loss: 0.0038 - val_accuracy: 0.4353\n",
            "Epoch 194/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.4121 - val_loss: 0.0112 - val_accuracy: 0.4353\n",
            "Epoch 195/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.4121 - val_loss: 0.0062 - val_accuracy: 0.4353\n",
            "Epoch 196/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.4121 - val_loss: 0.0060 - val_accuracy: 0.4353\n",
            "Epoch 197/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.4121 - val_loss: 0.0071 - val_accuracy: 0.4353\n",
            "Epoch 198/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.4121 - val_loss: 0.0084 - val_accuracy: 0.4353\n",
            "Epoch 199/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.4121 - val_loss: 0.0071 - val_accuracy: 0.4353\n",
            "Epoch 200/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.4121 - val_loss: 0.0046 - val_accuracy: 0.4353\n",
            "Training took 144.67989683151245 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "\n",
        "NN_regression_history = NN_regression_model.fit(XR_train, # Training features\n",
        "          yr_train, # Training labels\n",
        "          epochs=200,   # We'll stop after 10 epochs\n",
        "          batch_size=10, # \n",
        "          validation_split=0.10, # Use 10% of data to evaluate the loss. (val_loss)\n",
        "          verbose=1, #\n",
        "          )\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm6asdBQxnuD",
        "outputId": "ec40a8dd-f602-4cb2-d494-0017e67188ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NN_regression_history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "iAPoJFoTD5Le",
        "outputId": "c9d992f7-6db9-4765-ca0f-b481390e4a1a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(NN_regression_history.history[\"loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1vvR3XKTIEH"
      },
      "source": [
        "####Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Je8oT232THBE"
      },
      "outputs": [],
      "source": [
        "NN_regression_model.save(\"Optimal_Scheduling_Regression.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kdKNDX-_TKsm"
      },
      "outputs": [],
      "source": [
        "NN_regression_model.save(\"Optimal_Scheduling_Regression.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpuEeg0hEJZT"
      },
      "source": [
        "####Test model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wuEOpL0QELOR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "\n",
        "y_pred = (NN_regression_model.predict(XR_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw_VX72RFGmF",
        "outputId": "3bc25266-4c49-4a92-e4c7-844e6901f3e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.0147332],\n",
              "       [1.6194265],\n",
              "       [1.6330886],\n",
              "       ...,\n",
              "       [1.0235753],\n",
              "       [1.8622198],\n",
              "       [4.4048505]], dtype=float32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DKCE8r_06l9"
      },
      "source": [
        "###NN classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WFUNcWFC0_wm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "NN_classification_model = tf.keras.Sequential()\n",
        "NN_classification_model.add(layers.Dense(80, activation='relu', input_shape=(inputs.shape[1],)) )\n",
        "NN_classification_model.add(layers.Dense(40, activation='relu'))\n",
        "NN_classification_model.add(layers.Dense(1))\n",
        "NN_classification_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "NN_classification_model.build()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MpHJgl11ET9"
      },
      "source": [
        "####Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDNQApY91ET-",
        "outputId": "2ad60466-aa3f-4c25-d844-c81dd75ba964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "250/250 [==============================] - 2s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 2/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 3/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 4/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 5/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 6/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 7/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 8/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 9/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 10/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 11/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 12/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 13/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 14/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 15/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 16/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 17/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 18/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 19/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 20/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 21/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 22/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 23/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 24/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 25/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 26/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 27/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 28/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 29/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 30/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 31/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 32/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 33/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 34/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 35/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 36/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 37/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 38/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 39/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 40/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 41/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 42/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 43/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 44/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 45/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 46/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 47/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 48/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 49/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 50/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 51/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 52/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 53/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 54/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 55/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 56/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 57/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 58/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 59/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 60/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 61/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 62/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 63/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 64/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 65/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 66/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 67/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 68/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 69/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 70/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 71/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 72/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 73/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 74/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 75/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 76/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 77/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 78/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 79/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 80/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 81/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 82/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 83/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 84/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 85/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 86/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 87/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 88/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 89/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 90/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 91/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 92/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 93/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 94/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 95/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 96/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 97/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 98/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 99/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 100/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 101/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 102/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 103/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 104/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 105/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 106/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 107/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 108/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 109/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 110/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 111/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 112/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 113/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 114/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 115/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 116/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 117/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 118/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 119/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 120/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 121/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 122/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 123/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 124/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 125/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 126/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 127/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 128/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 129/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 130/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 131/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 132/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 133/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 134/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 135/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 136/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 137/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 138/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 139/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 140/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 141/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 142/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 143/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 144/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 145/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 146/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 147/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 148/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 149/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 150/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 151/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 152/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 153/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 154/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 155/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 156/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 157/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 158/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 159/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 160/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 161/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 162/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 163/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 164/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 165/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 166/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 167/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 168/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 169/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 170/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 171/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 172/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 173/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 174/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 175/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 176/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 177/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 178/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 179/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 180/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 181/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 182/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 183/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 184/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 185/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 186/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 187/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 188/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 189/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 190/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 191/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 192/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 193/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 194/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 195/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 196/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 197/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 198/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 199/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Epoch 200/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 3.9826e-07 - accuracy: 0.4065 - val_loss: 3.8164e-07 - val_accuracy: 0.4317\n",
            "Training took 202.33007645606995 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "\n",
        "NN_classification_history = NN_classification_model.fit(XC_train, # Training features\n",
        "          yc_train, # Training labels\n",
        "          epochs=200,   # We'll stop after 10 epochs\n",
        "          batch_size=10, # \n",
        "          validation_split=0.10, # Use 10% of data to evaluate the loss. (val_loss)\n",
        "          verbose=1, #\n",
        "          )\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MGXdA-h1ET_",
        "outputId": "7d74838f-6a51-4353-d133-b402f03233f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NN_classification_history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "fOBm2FEX1EUA",
        "outputId": "f78b638e-fb07-448d-b738-ddd49a7ec0ee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(NN_classification_history.history[\"loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jPAzJPU1tPE"
      },
      "source": [
        "####Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hVpjV2UL1tPW"
      },
      "outputs": [],
      "source": [
        "NN_classification_model.save(\"Optimal_Scheduling_Classification.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GJLJelmb1tPW"
      },
      "outputs": [],
      "source": [
        "NN_classification_model.save(\"Optimal_Scheduling_Classification.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c4NiQFx134Q"
      },
      "source": [
        "####Test model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PzOP-N4D134R"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "\n",
        "y_pred = (NN_classification_model.predict(XC_test) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyXrApuFFTeT",
        "outputId": "0d881f16-99ba-4f6d-f7da-2ce1b5a04dea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdBE5Rb_134S",
        "outputId": "59ddca3a-6891-421f-c2f3-737555b839a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Network Confusion matrix\n",
            "- x-axis is true labels.\n",
            "- y-axis is predicted labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[531,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 14,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [299,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 78,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [180,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 47,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 32,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [100,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = yc_test\n",
        "print('Neural Network Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "P60eYxW_134T",
        "outputId": "6093ce50-488b-4102-946d-7c0485a2eb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.99      0.57       538\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00        23\n",
            "           3       0.00      0.00      0.00        14\n",
            "           4       0.00      0.00      0.00       299\n",
            "           5       0.00      0.00      0.00        78\n",
            "           6       0.00      0.00      0.00       180\n",
            "           7       0.00      0.00      0.00        83\n",
            "           8       0.00      0.00      0.00        32\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00       100\n",
            "          11       0.00      0.00      0.00        18\n",
            "          12       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.39      1367\n",
            "   macro avg       0.03      0.08      0.04      1367\n",
            "weighted avg       0.16      0.39      0.22      1367\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(yc_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brHHv-QET768"
      },
      "source": [
        "###Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V7M0mpg1T7cO"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBDSeX5sFT65"
      },
      "source": [
        "####Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijBG8TmXF30H",
        "outputId": "f70ff645-a09a-408a-8fd0-e6569eb05e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training took 0.010987997055053711 seconds\n"
          ]
        }
      ],
      "source": [
        "DTR_model = DecisionTreeRegressor()\n",
        "import time\n",
        "t0 = time.time()\n",
        "DTR_model.fit(XR_train, yr_train)\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cuEBRsuBUM8D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFQhT93qGRNU"
      },
      "source": [
        "####Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vvR0U2vkGRNU"
      },
      "outputs": [],
      "source": [
        "# make predictions for test data\n",
        "DTR_predictions = DTR_model.predict(XR_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "95RLWtIbFeQT",
        "outputId": "a6752c35-71ab-44e6-aa4e-6a9b54f49867"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 1.5022245 , 1.62006273, ..., 1.        , 1.86892436,\n",
              "       4.38017881])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DTR_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tJZDC206UjsV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrecx-f-2Y91"
      },
      "source": [
        "###Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zqjRA9_s2Y-G"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujIFy2o52Y-H"
      },
      "source": [
        "####Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgK4XYeK2Y-H",
        "outputId": "9219ba64-6078-455e-cb8b-59ac8b52f618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training took 0.008457422256469727 seconds\n"
          ]
        }
      ],
      "source": [
        "DTC_model = DecisionTreeClassifier()\n",
        "import time\n",
        "t0 = time.time()\n",
        "DTC_model.fit(XC_train, yc_train)\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e_ocmBCo2Y-I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idYbqDHq2Y-I"
      },
      "source": [
        "####Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OoHQjtFu2Y-I"
      },
      "outputs": [],
      "source": [
        "# make predictions for test data\n",
        "y_pred = DTC_model.predict(XC_test)\n",
        "DTC_predictions = [round(value) for value in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzlJCd1V2Y-J",
        "outputId": "7018cf09-0189-43ca-ff00-f5ab391eaf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decion tree Test accuracy: 99.56%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(yc_test, DTC_predictions)\n",
        "print(\"Decion tree Test accuracy: %.2f%%\" % (accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaRftZMN2Y-J",
        "outputId": "c6d1bc69-5ee4-4566-fa1f-d3847907cce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision tree Confusion matrix\n",
            "- x-axis is true labels.\n",
            "- y-axis is predicted labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[538,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0, 297,   0,   0,   0,   1,   0,   0,   1,   0],\n",
              "       [  0,   0,   0,   0,  78,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0, 180,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  83,   0,   0,   0,   0,   0],\n",
              "       [  0,   1,   0,   0,   0,   0,   0,  31,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  99,   1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = yc_test\n",
        "print('Decision tree Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
        "cm = confusion_matrix(y_true, DTC_predictions)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiBRdy9f2Y-J",
        "outputId": "42b0e607-0c6f-4e63-804d-87e9163dcc3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       538\n",
            "           2       0.96      1.00      0.98        23\n",
            "           3       1.00      1.00      1.00        14\n",
            "           4       1.00      0.99      1.00       299\n",
            "           5       1.00      1.00      1.00        78\n",
            "           6       1.00      1.00      1.00       180\n",
            "           7       1.00      1.00      1.00        83\n",
            "           8       0.97      0.97      0.97        32\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       1.00      0.99      0.99       100\n",
            "          11       0.90      1.00      0.95        18\n",
            "          12       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           1.00      1367\n",
            "   macro avg       0.82      0.83      0.82      1367\n",
            "weighted avg       0.99      1.00      0.99      1367\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(yc_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ylX2d0lW2Y-K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbz4VgzyE5Hu"
      },
      "source": [
        "###Gradient Boosting machine | Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VoRy9RC6E4j5"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFz19KrOFWP5"
      },
      "source": [
        "####Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F89VdMsFA7V",
        "outputId": "91b0beba-d604-454a-98ea-7544124e1fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12:22:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Training took 0.45526671409606934 seconds\n"
          ]
        }
      ],
      "source": [
        "# fit model no training data\n",
        "XGBR_model = XGBRegressor()\n",
        "import time\n",
        "t0 = time.time()\n",
        "XGBR_model.fit(XR_train, yr_train)\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXyzhZ3uFSpF"
      },
      "source": [
        "####Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HqE63eewFR40"
      },
      "outputs": [],
      "source": [
        "# make predictions for test data\n",
        "y_pred = XGBR_model.predict(XR_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA9INkvFGVdh",
        "outputId": "7b34c487-852d-4b26-bb0f-d493573875da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.0037758, 1.5994779, 1.6040826, ..., 1.0022085, 1.8299105,\n",
              "       4.2918715], dtype=float32)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AKVAvL2_GaAc",
        "outputId": "43d53fc3-9f4c-4680-ea7c-361f5fd1ae83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ecdc4223-5e22-4256-b9f5-63f7d82a93b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Output power (MW)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2351</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>1.501902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1582</th>\n",
              "      <td>1.619953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>6.372317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1427</th>\n",
              "      <td>1.839589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2304</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3966</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1413</th>\n",
              "      <td>1.870826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>4.377234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1367 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecdc4223-5e22-4256-b9f5-63f7d82a93b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecdc4223-5e22-4256-b9f5-63f7d82a93b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecdc4223-5e22-4256-b9f5-63f7d82a93b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Output power (MW)\n",
              "2351           1.000000\n",
              "1966           1.501902\n",
              "1582           1.619953\n",
              "296            6.372317\n",
              "149            1.000000\n",
              "...                 ...\n",
              "1427           1.839589\n",
              "2304           1.000000\n",
              "3966           1.000000\n",
              "1413           1.870826\n",
              "859            4.377234\n",
              "\n",
              "[1367 rows x 1 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yr_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Y9fa-g_3r0Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S-eBTSJ3r_B"
      },
      "source": [
        "###Gradient Boosting machine | Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iPFD2mAa3r_B"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W1IvteE3r_C"
      },
      "source": [
        "####Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "20VYW3Nc3r_C",
        "outputId": "553aa56b-2e37-4db1-978b-fb08dd5d8f3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training took 0.6716763973236084 seconds\n"
          ]
        }
      ],
      "source": [
        "# fit model no training data\n",
        "XGBC_model = XGBClassifier()\n",
        "import time\n",
        "t0 = time.time()\n",
        "XGBC_model.fit(XC_train, yc_train)\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVHvUVmk3r_C"
      },
      "source": [
        "####Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p6AVs8jf3r_D"
      },
      "outputs": [],
      "source": [
        "# make predictions for test data\n",
        "y_pred = XGBC_model.predict(XC_test)\n",
        "predictions = [round(value) for value in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVSCKP3E3r_D",
        "outputId": "a65634f7-1d74-4a6f-d804-37f681f67a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGB Classifier Test accuracy: 99.41%\n"
          ]
        }
      ],
      "source": [
        "# evaluate predictions\n",
        "accuracy = accuracy_score(yc_test, predictions)\n",
        "print(\"XGB Classifier Test accuracy: %.2f%%\" % (accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLnJE6VI3r_D",
        "outputId": "fc385ba8-621e-4eff-f637-503fe8138197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGB Classifier Confusion matrix\n",
            "- x-axis is true labels.\n",
            "- y-axis is predicted labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[538,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0, 297,   0,   0,   0,   1,   0,   0,   1,   0],\n",
              "       [  0,   0,   0,   0,  78,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0, 180,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  83,   0,   0,   0,   0,   0],\n",
              "       [  0,   1,   0,   0,   0,   0,   0,  31,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  99,   1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = yc_test\n",
        "print('XGB Classifier Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
        "cm = confusion_matrix(y_true, DTC_predictions)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXn9x46d3r_E",
        "outputId": "b3e28157-264c-4817-ec32-13b366a0d057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       538\n",
            "           2       0.96      1.00      0.98        23\n",
            "           3       1.00      0.86      0.92        14\n",
            "           4       1.00      1.00      1.00       299\n",
            "           5       0.99      1.00      0.99        78\n",
            "           6       1.00      1.00      1.00       180\n",
            "           7       1.00      1.00      1.00        83\n",
            "           8       0.91      0.94      0.92        32\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.99      1.00      1.00       100\n",
            "          11       1.00      0.94      0.97        18\n",
            "          12       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.99      1367\n",
            "   macro avg       0.82      0.81      0.82      1367\n",
            "weighted avg       0.99      0.99      0.99      1367\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(yc_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MzTD9StV3r_E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHqm84rw0ck"
      },
      "source": [
        "###Random forest | Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a6JQ3Vmw_Kw"
      },
      "source": [
        "##Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_-D4NBcpw20v",
        "outputId": "e7f33b72-c554-45c1-fe11-777918dc74a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=2, random_state=0)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "Random_Forest_Classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "Random_Forest_Classifier.fit(XC_train, yc_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksXpjk6Gt2Vz"
      },
      "source": [
        "####Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UTD4w_Yet2V0"
      },
      "outputs": [],
      "source": [
        "# make predictions for test data\n",
        "y_pred = Random_Forest_Classifier.predict(XC_test)\n",
        "RFC_predictions = [round(value) for value in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI-ExVvAt2V0",
        "outputId": "5483baa2-6dc3-4aba-87ca-e60705520b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Test accuracy: 80.25%\n"
          ]
        }
      ],
      "source": [
        "# evaluate predictions\n",
        "accuracy = accuracy_score(yc_test, RFC_predictions)\n",
        "print(\"Random Forest Classifier Test accuracy: %.2f%%\" % (accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AIRWghAt2V1",
        "outputId": "652c968d-d198-4dff-9444-19ffb8b862b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Confusion matrix\n",
            "- x-axis is true labels.\n",
            "- y-axis is predicted labels\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[538,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,  23,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,  14,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0, 299,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   4,   0,  74,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0, 180,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   3,  80,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,  20,   0,   0,  12,   0,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0, 100,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,  18,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = yc_test\n",
        "print('Random Forest Classifier Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
        "cm = confusion_matrix(y_true, RFC_predictions)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1BkfeZdt2V2",
        "outputId": "c5d75da7-6df5-4a2b-e0ec-b481692e5460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       538\n",
            "           2       0.00      0.00      0.00        23\n",
            "           3       0.00      0.00      0.00        14\n",
            "           4       0.63      1.00      0.77       299\n",
            "           5       0.00      0.00      0.00        78\n",
            "           6       0.70      1.00      0.82       180\n",
            "           7       0.87      0.96      0.91        83\n",
            "           8       0.00      0.00      0.00        32\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00       100\n",
            "          11       0.00      0.00      0.00        18\n",
            "          12       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.80      1367\n",
            "   macro avg       0.27      0.33      0.29      1367\n",
            "weighted avg       0.67      0.80      0.73      1367\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(yc_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ot0LpcHHt2V2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}